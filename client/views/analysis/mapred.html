<template name="mapred">
<div id="mapred" class="container-fluid">
  <div class="row">
    <div class="col-lg-6 col-lg-offset-0 col-md-8 col-md-offset-2 col-xs-12"><img src="images/mapred.svg" style="width:100%;"></div>
    <div class="col-lg-6 col-lg-offset-0 col-md-8 col-md-offset-2 col-xs-12">
      <div class="col-xs-12 textdesc">
        <p>I've put a sample MapReduce job and <a href="https://github.com/bgrayburn/itemSetCount" target="_blank">code up on Github here</a> using the Python multiprocessing library and MongoDB to take do local MapReduce jobs using multicore processing to create paraellelism.
        </p>
        <p>
          If a process can be described in the steps pictured, batches made from the complete dataset can be run in multiple subprocesses that use multiple CPU cores for greater performance. Common examples of a process fitting this model included:
        </p>
        <table class="col-xs-6 col-xs-offset-3" style="border: 1px darkgray;">
          <tr><td>Counting groupings of items in purchase transactions</td></tr>
          <tr><td>Finding the frequency of words and sets of words in text documents</td></tr>
          <tr><td>Determining which documents in a filesystem are over 1GB</td></tr>
        </table>
      </div>

      <div class="col-xs-12 textdesc">
        <p>
          To implement this kind of setup, I use <a href="https://spark.apache.org/" target="_blank">Spark</a> for Scala or <a href="https://github.com/Yelp/mrjob" target="_blank">mrjob</a> for Python, depending on the complexity of the job.
        </p>
      </div>
      <div class="col-xs-12 textdesc">
        <p>
          The first time I had to count common combinations of items in a large number of transactions, I decided I wanted to build a mapreduce job wihtout libraries to really understand what was happening. I've made the <a href="https://github.com/bgrayburn/itemSetCount" target="_blank">code available here</a>.
        </p>
      </div>
    </div>
  </div>
</div>
</template>